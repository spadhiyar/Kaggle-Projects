# -*- coding: utf-8 -*-
"""WIDS_Datathon_Undersampler_Resnet50_1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BMEHDkm6s5t6f5lE21uGZDk1GtOM45z-
"""

#!pip install keras_metrics

#!pip install tqdm

import pandas as pd
import numpy as np
import keras
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten, GlobalAveragePooling2D, BatchNormalization
from keras.layers import Conv2D, MaxPooling2D
from keras.utils import to_categorical
from keras.preprocessing import image
from keras import applications
from keras.applications import ResNet50
from keras.models import Sequential,Model,load_model
from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D,GlobalAveragePooling2D
import keras_metrics
from sklearn.model_selection import train_test_split
from keras.utils import to_categorical
from tqdm import tqdm
import os, sys

from keras.applications import VGG19
from keras.applications.vgg19 import preprocess_input
from keras import optimizers

"""trainLabelsPath = "traininglabels.csv"
trainImagesPath = "/Users/HS/Downloads/widsdatathon2019/train_images/"

testFolderPath = "/Users/HS/Downloads/widsdatathon2019/leaderboard_test_data"
testImagesPath = "/Users/HS/Downloads/widsdatathon2019/leaderboard_test_data/"

holdFolderPath = "/Users/HS/Downloads/widsdatathon2019/leaderboard_holdout_data"
holdImagesPath = "/Users/HS/Downloads/widsdatathon2019/leaderboard_holdout_data/"

subFilePath = "finalSubmission_underSamp.csv"
"""

trainLabelsPath = "/home/ubuntu/WIDS/traininglabels.csv"
trainImagesPath = "/home/ubuntu/WIDS/train_images/"

testFolderPath = "/home/ubuntu/WIDS/leaderboard_test_data"
testImagesPath = "/home/ubuntu/WIDS/leaderboard_test_data/"

holdFolderPath = "/home/ubuntu/WIDS/leaderboard_holdout_data"
holdImagesPath = "/home/ubuntu/WIDS/leaderboard_holdout_data/"

subFilePath = "finalSubmission_underSamp_resnet_1.csv"

"""# Upload training data file"""

df = pd.read_csv(trainLabelsPath)

df.info()

df[df.has_oilpalm == 1].count() # only 6% of the images have palm oil plantations

df.score.sort_values()[:5]
# some images have very small scores. Perhaps use a threshold like 0.5 and give 0.5 or less, label 0

df = df.sort_values(by='image_id').reset_index(drop=True)

df_hasPalm = df[df.has_oilpalm == 1]
df_noPalm = df[(df.has_oilpalm == 0) & (df.score == 1)]

df_noPalm_samp = df_noPalm.sample(1000)
df_noPalm_samp.shape

df_final = df_hasPalm.append(df_noPalm_samp).sort_values(by='image_id').reset_index(drop=True)

df_final.head()

type(df_final.image_id)

# Reading images from a folder and converting to numpy array
train_image = []
for i in tqdm(range(len(df_final))):
    img = image.load_img(trainImagesPath + df_final.image_id[i], target_size=(256,256,1))
    img = image.img_to_array(img)
    img = img/255
    
    
    train_image.append(img)
X = np.array(train_image)
X

y = df_final['has_oilpalm'].values
#y = to_categorical(y)
y

X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2,stratify=y)

X_train.shape, X_test.shape, y_train.shape, y_test.shape

#base_model = applications.resnet50.ResNet50(weights= None, include_top=False, input_shape= (150,150,3))

#x = base_model.output
#x = GlobalAveragePooling2D()(x)
#x = Dropout(0.7)(x)
#predictions = Dense(2, activation= 'sigmoid')(x)
#model = Model(inputs = base_model.input, outputs = predictions)

#model = Sequential()

#model.add(VGG19(include_top=False, weights='imagenet', input_shape= (256,256,3)))

#model.summary()

# freezing layer

#for layer in model.layers[:10]:
    #layer.trainable = False

#fully connected layer

#x = model.output
#x = Flatten()(x)
#x = Dense(1024, activation="relu")(x)
#x = Dropout(0.5)(x)
#x = Dense(1024, activation="relu")(x)


#prediction = Dense(1, activation="sigmoid")(x)

# final model

#model_final = Model(input=model.input, output = prediction)

model = Sequential()

model.add(ResNet50(weights='imagenet', include_top=False,input_shape= (256,256,3)))
model.add(BatchNormalization())
model.add(GlobalAveragePooling2D())

model.add(Dense(1024, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(1024, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(1, activation='sigmoid'))

#for layer in model.layers[:25]:
    #layer.trainable = False


#last_layer = model.output

# add a global spatial average pooling layer
#x = GlobalAveragePooling2D()(last_layer)

# Add fully connected & dropout layers
#x = Dense(512, activation='relu', name='fc-1')(x)
#x = Dropout(0.5)(x)
#x = Dense(256, activation='relu', name='fc-2')(x)
#x = Dropout(0.5)(x)

# softmax layer for 5 classes
#out = Dense(1, activation='sigmoid', name='output_layer')(x)

#model_final = Model(model.input, outputs=out)

from keras.optimizers import SGD, Adam
# sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)
adam = Adam(lr=0.0001)
model.compile(optimizer=adam, loss='binary_crossentropy',metrics = [keras_metrics.precision(), keras_metrics.recall(),'accuracy'])

#model.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['accuracy'])

# Build model with training data and get loss and accuracy scores
model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test))

"""# Leaderboard Test Data Prediction"""

testpath = testFolderPath
testimagesList = sorted(os.listdir(testpath))
testimagesList

leaderboard_test_pred = pd.DataFrame(testimagesList , columns=['image_id'])
leaderboard_test_pred

test_image = []
for i in tqdm(range(len(testimagesList))):
    img = image.load_img(testImagesPath + testimagesList[i], target_size=(256,256,1))
    img = image.img_to_array(img)
    img = img/255
    test_image.append(img)
test = np.array(test_image)
test

# making predictions
prediction = model.predict(test)

leaderboard_test_pred['has_oilpalm'] = prediction

leaderboard_test_pred.has_oilpalm.unique()

leaderboard_test_pred[leaderboard_test_pred.has_oilpalm == 1]

"""# Leaderboard Holdback Data Prediction"""

holdpath = holdFolderPath
holdimagesList = sorted(os.listdir(holdpath))
holdimagesList

leaderboard_hold_pred = pd.DataFrame(holdimagesList , columns=['image_id'])
leaderboard_hold_pred

hold_image = []
for i in tqdm(range(len(holdimagesList))):
    img = image.load_img(holdImagesPath + holdimagesList[i], target_size=(256,256,1))
    img = image.img_to_array(img)
    img = img/255
    hold_image.append(img)
hold = np.array(hold_image)
hold

# making predictions
prediction = model.predict(hold)

leaderboard_hold_pred['has_oilpalm'] = prediction

leaderboard_hold_pred.has_oilpalm.unique()

leaderboard_test_pred[leaderboard_test_pred.has_oilpalm == 1]

"""# Building submission file"""

leaderboard_test_pred.shape

leaderboard_hold_pred.shape

finalSubmission = leaderboard_test_pred.append(leaderboard_hold_pred)
finalSubmission.shape

finalSubmission.head()

finalSubmission.to_csv(subFilePath,index=False)

